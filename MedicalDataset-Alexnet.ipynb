{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-14T12:34:47.396058Z","iopub.status.busy":"2023-05-14T12:34:47.395622Z","iopub.status.idle":"2023-05-14T12:34:47.405988Z","shell.execute_reply":"2023-05-14T12:34:47.404316Z","shell.execute_reply.started":"2023-05-14T12:34:47.396027Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import os\n","import time\n","import cv2"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Loading the dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T13:03:55.920485Z","iopub.status.busy":"2023-05-14T13:03:55.919999Z","iopub.status.idle":"2023-05-14T13:03:55.926653Z","shell.execute_reply":"2023-05-14T13:03:55.925408Z","shell.execute_reply.started":"2023-05-14T13:03:55.920446Z"},"trusted":true},"outputs":[],"source":["#Define the classes and their labels\n","classes = ['AbdomenCT', 'ChestCT', 'HeadCT', 'ChestXRay', 'Hand', 'BreastMRI']"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T12:49:12.858774Z","iopub.status.busy":"2023-05-14T12:49:12.858402Z","iopub.status.idle":"2023-05-14T12:49:12.865035Z","shell.execute_reply":"2023-05-14T12:49:12.863418Z","shell.execute_reply.started":"2023-05-14T12:49:12.858746Z"},"trusted":true},"outputs":[],"source":["#Define the class directories\n","abdomen_DIR = '../FCV2/AbdomenCT'\n","breastmri_DIR = '../FCV2/BreastMRI'\n","chestct_DIR = '../FCV2/ChestCT'\n","cxr_DIR = '../FCV2/CXR'\n","hand_DIR = '../FCV2/Hand'\n","headct_DIR = '../FCV2/HeadCT'\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T13:07:54.390945Z","iopub.status.busy":"2023-05-14T13:07:54.390526Z","iopub.status.idle":"2023-05-14T13:07:54.401894Z","shell.execute_reply":"2023-05-14T13:07:54.400169Z","shell.execute_reply.started":"2023-05-14T13:07:54.390910Z"},"trusted":true},"outputs":[],"source":["# Creates lists of the image paths and their labels (we'll make a dataframe out of these)\n","X = []\n","y = []\n","\n","def makeTrainData(className, classDIR):\n","    for img in os.listdir(classDIR):\n","        path = os.path.join(classDIR, img)\n","        X.append(path)\n","        y.append(className)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T13:07:55.814533Z","iopub.status.busy":"2023-05-14T13:07:55.814127Z","iopub.status.idle":"2023-05-14T13:07:56.067393Z","shell.execute_reply":"2023-05-14T13:07:56.066334Z","shell.execute_reply.started":"2023-05-14T13:07:55.814500Z"},"trusted":true},"outputs":[],"source":["# Add each class to the X and y list\n","\n","makeTrainData('AbdomenCT', abdomen_DIR)\n","\n","makeTrainData('ChestCT', chestct_DIR)\n","\n","makeTrainData('HeadCT', headct_DIR)\n","\n","makeTrainData('ChestXRay', cxr_DIR)\n","\n","makeTrainData('Hand', hand_DIR)\n","\n","makeTrainData('BreastMRI', breastmri_DIR)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets\n","train_val_images, test_images, train_val_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Split the train_val data into training and validation sets\n","train_images, val_images, train_labels, val_labels = train_test_split(train_val_images, train_val_labels, test_size=0.2, random_state=42)\n","\n","train_images += val_images\n","train_labels += val_labels\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Preprocessing and augmenting the data"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T13:04:37.370911Z","iopub.status.busy":"2023-05-14T13:04:37.370426Z","iopub.status.idle":"2023-05-14T13:04:37.377706Z","shell.execute_reply":"2023-05-14T13:04:37.376381Z","shell.execute_reply.started":"2023-05-14T13:04:37.370875Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T13:58:03.120809Z","iopub.status.busy":"2023-05-14T13:58:03.120109Z","iopub.status.idle":"2023-05-14T13:58:03.142869Z","shell.execute_reply":"2023-05-14T13:58:03.141438Z","shell.execute_reply.started":"2023-05-14T13:58:03.120774Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>../FCV2/CXR\\000484.jpeg</td>\n","      <td>ChestXRay</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>../FCV2/BreastMRI\\000421.jpeg</td>\n","      <td>BreastMRI</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>../FCV2/HeadCT\\000755.jpeg</td>\n","      <td>HeadCT</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>../FCV2/Hand\\003880.jpeg</td>\n","      <td>Hand</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>../FCV2/BreastMRI\\002538.jpeg</td>\n","      <td>BreastMRI</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            path      class\n","0        ../FCV2/CXR\\000484.jpeg  ChestXRay\n","1  ../FCV2/BreastMRI\\000421.jpeg  BreastMRI\n","2     ../FCV2/HeadCT\\000755.jpeg     HeadCT\n","3       ../FCV2/Hand\\003880.jpeg       Hand\n","4  ../FCV2/BreastMRI\\002538.jpeg  BreastMRI"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.DataFrame({'path': train_images, 'class': train_labels})\n","testdata = pd.DataFrame({'path': test_images, 'class': test_labels})\n","data.head()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T13:58:05.696194Z","iopub.status.busy":"2023-05-14T13:58:05.695780Z","iopub.status.idle":"2023-05-14T13:58:05.729781Z","shell.execute_reply":"2023-05-14T13:58:05.728545Z","shell.execute_reply.started":"2023-05-14T13:58:05.696164Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>class</th>\n","      <th>AbdomenCT</th>\n","      <th>BreastMRI</th>\n","      <th>ChestCT</th>\n","      <th>ChestXRay</th>\n","      <th>Hand</th>\n","      <th>HeadCT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>../FCV2/CXR\\000484.jpeg</td>\n","      <td>ChestXRay</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>../FCV2/BreastMRI\\000421.jpeg</td>\n","      <td>BreastMRI</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>../FCV2/HeadCT\\000755.jpeg</td>\n","      <td>HeadCT</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>../FCV2/Hand\\003880.jpeg</td>\n","      <td>Hand</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>../FCV2/BreastMRI\\002538.jpeg</td>\n","      <td>BreastMRI</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            path      class  AbdomenCT  BreastMRI  ChestCT   \n","0        ../FCV2/CXR\\000484.jpeg  ChestXRay      False      False    False  \\\n","1  ../FCV2/BreastMRI\\000421.jpeg  BreastMRI      False       True    False   \n","2     ../FCV2/HeadCT\\000755.jpeg     HeadCT      False      False    False   \n","3       ../FCV2/Hand\\003880.jpeg       Hand      False      False    False   \n","4  ../FCV2/BreastMRI\\002538.jpeg  BreastMRI      False       True    False   \n","\n","   ChestXRay   Hand  HeadCT  \n","0       True  False   False  \n","1      False  False   False  \n","2      False  False    True  \n","3      False   True   False  \n","4      False  False   False  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["one_hot_encoded = pd.get_dummies(data['class'])\n","data = pd.concat([data, one_hot_encoded], axis=1)\n","data.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T13:58:40.094729Z","iopub.status.busy":"2023-05-14T13:58:40.094273Z","iopub.status.idle":"2023-05-14T14:00:49.965405Z","shell.execute_reply":"2023-05-14T14:00:49.964074Z","shell.execute_reply.started":"2023-05-14T13:58:40.094697Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 3840 validated image filenames belonging to 6 classes.\n","Found 960 validated image filenames belonging to 6 classes.\n","Found 1200 validated image filenames belonging to 6 classes.\n"]}],"source":["# Creating a datagen to augment the image with rotations, flips, rescales, shear and zoom\n","# A 80-20 split is being used for training and validation\n","datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest',\n","    validation_split=0.2\n",")\n","\n","# Create the training generator\n","train_generator = datagen.flow_from_dataframe(\n","    dataframe=data,\n","    x_col='path',\n","    y_col='class',\n","    target_size=(227, 227),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='training',\n","    shuffle=True\n",")\n","\n","# Create the testing generator\n","validation_generator = datagen.flow_from_dataframe(\n","    dataframe=data,\n","    x_col=\"path\",\n","    y_col=\"class\",\n","    target_size=(227, 227),\n","    batch_size=32,\n","    class_mode=\"categorical\",\n","    subset=\"validation\",\n","    shuffle=True\n",")\n","\n","\n","test_generator = datagen.flow_from_dataframe(\n","    dataframe=testdata,\n","    x_col=\"path\",\n","    y_col=\"class\",\n","    target_size=(227, 227),\n","    batch_size=32,\n","    class_mode=\"categorical\",\n","    shuffle=False\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Defining the model - Alexnet"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T14:01:21.795546Z","iopub.status.busy":"2023-05-14T14:01:21.795146Z","iopub.status.idle":"2023-05-14T14:01:21.801586Z","shell.execute_reply":"2023-05-14T14:01:21.800101Z","shell.execute_reply.started":"2023-05-14T14:01:21.795515Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T14:03:56.536658Z","iopub.status.busy":"2023-05-14T14:03:56.536211Z","iopub.status.idle":"2023-05-14T14:03:57.261429Z","shell.execute_reply":"2023-05-14T14:03:57.260239Z","shell.execute_reply.started":"2023-05-14T14:03:56.536626Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 27, 27, 256)       614656    \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 13, 13, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 13, 13, 384)       885120    \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 13, 13, 384)       1327488   \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 13, 13, 256)       884992    \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 9216)              0         \n","                                                                 \n"," dense (Dense)               (None, 4096)              37752832  \n","                                                                 \n"," dropout (Dropout)           (None, 4096)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 6)                 24582     \n","                                                                 \n","=================================================================\n","Total params: 58,305,926\n","Trainable params: 58,305,926\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model = Sequential()\n","\n","# Convolutional layers\n","model.add(Conv2D(96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)))\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n","model.add(Conv2D(256, kernel_size=(5,5), strides=(1,1), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n","model.add(Conv2D(384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'))\n","model.add(Conv2D(384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'))\n","model.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n","\n","# Fully connected layers\n","model.add(Flatten())\n","model.add(Dense(4096, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(4096, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(6, activation='softmax'))\n","\n","# Compile the model with Adam optimizer and Accuracy as our metric\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.summary()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Training the Model"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T14:04:01.533477Z","iopub.status.busy":"2023-05-14T14:04:01.533014Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","120/120 [==============================] - 207s 2s/step - loss: 0.8675 - accuracy: 0.6776 - val_loss: 0.2537 - val_accuracy: 0.9292\n","Epoch 2/5\n","120/120 [==============================] - 228s 2s/step - loss: 0.2163 - accuracy: 0.9331 - val_loss: 0.1271 - val_accuracy: 0.9667\n","Epoch 3/5\n","120/120 [==============================] - 209s 2s/step - loss: 0.1690 - accuracy: 0.9508 - val_loss: 0.1418 - val_accuracy: 0.9625\n","Epoch 4/5\n","120/120 [==============================] - 208s 2s/step - loss: 0.2700 - accuracy: 0.9279 - val_loss: 0.1091 - val_accuracy: 0.9698\n","Epoch 5/5\n","120/120 [==============================] - 211s 2s/step - loss: 0.1298 - accuracy: 0.9578 - val_loss: 0.0547 - val_accuracy: 0.9812\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x1ac7e68e410>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(train_generator, epochs=5, validation_data=validation_generator)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Evaluating and testing the model"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["38/40 [===========================>..] - ETA: 0s - loss: 0.0651 - accuracy: 0.9825WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n","40/40 [==============================] - 16s 406ms/step - loss: 0.0651 - accuracy: 0.9825\n","\n","Accuracy: 98.25%\n"]}],"source":["score = model.evaluate(test_generator, steps=40)\n","print(f\"\\nAccuracy: {round(score[1]*100, 2)}%\")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'test_generator' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Generate predictions for the test images\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_steps \u001b[39m=\u001b[39m test_generator\u001b[39m.\u001b[39msamples \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m32\u001b[39m\n\u001b[0;32m      3\u001b[0m test_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_generator, steps\u001b[39m=\u001b[39mtest_steps, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Define a function to convert predicted labels to class names\u001b[39;00m\n","\u001b[1;31mNameError\u001b[0m: name 'test_generator' is not defined"]}],"source":["# Generate predictions for the test images\n","test_steps = test_generator.samples // 32\n","test_pred = model.predict(test_generator, steps=test_steps, verbose=2)\n","\n","# Define a function to convert predicted labels to class names\n","def get_class_name(pred):\n","    idx = np.argmax(pred)\n","    for class_name, class_idx in test_generator.class_indices.items():\n","        if class_idx == idx:\n","            return class_name\n","\n","\n","# Define a function to plot an image and its predicted and ground truth labels\n","def plot_image(image, pred_label, true_label):\n","    plt.imshow(image)\n","    plt.title('Prediction: {}\\nTrue label: {}'.format(pred_label, true_label))\n","    plt.axis('off')\n","    plt.show()\n","\n","# Loop through the test images and plot them alongside their predicted and ground truth labels\n","for i in range(50):\n","    # Get the next test image and its true label\n","    image, true_label = test_generator.next()\n","    \n","    # Get the predicted label for this image\n","    pred_label = get_class_name(test_pred[i])\n","    \n","    # Plot the image and its predicted and true labels\n","    plot_image(image[0], pred_label, true_label[0])\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
